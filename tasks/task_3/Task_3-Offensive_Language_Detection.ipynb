{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwlCu+c4hdEUEIa7SraqTj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Offensive Language Detection in Social Media\n","\n","Offensive language detection in social media refers to the process of identifying and flagging content that contains language or expressions that are considered inappropriate, disrespectful, harmful, or offensive to certain groups or individuals.\n","\n","The goal of offensive language detection is to help maintain a respectful and safe online environment by automatically identifying and filtering out content that may violate community guidelines or terms of service on social media platforms. It's used by social media companies to moderate user-generated content, protect users from harassment or abuse, and prevent the spread of harmful or inappropriate content."],"metadata":{"id":"Iy47PZH-Y6nr"}},{"cell_type":"markdown","source":["## The Task\n","After Elon Musk's acquisition of X, former Twitter, hate speech skyrocketed on the social media platform [[1]]. Given Mr. Musk's occasional difficulty in identifying offensive language, it may be beneficial to assist him by developing a model for offensive language detection.\n","\n","Your task is to construct a model, train it using an annotated dataset, and determine whether any of the following tweets from the former President of the United States, Donald J. Trump, could be deemed offensive.\n","\n","> I heard poorly rated @Morning_Joe speaks badly of me (don't watch anymore). Then how come low I.Q. Crazy Mika, along with Psycho Joe, came to Mar-a-Lago 3 nights in a row around New Year's Eve, and insisted on joining me. She was bleeding badly from a face-lift. I said no!\n","\n","> .@ariannahuff is unattractive both inside and out. I fully understand why her former husband left her for a man- he made a good decision.\n","\n","> Despite the constant negative press covfefe\n","\n","> In the 1920's people were worried about global cooling--it never happened. Now it's global warming. Give me a break!\n","\n","> Sorry losers and haters, but my I.Q. is one of the highest -and you all know it! Please don't feel so stupid or insecure,it's not your fault\n","\n","> Did Crooked Hillary help disgusting (check out sex tape and past) Alicia M become a U.S. citizen so she could use her in the debate?\n","\n","<img src=\"https://raw.githubusercontent.com/bbirke/ml-python/main/images/trump.jpg\" alt=\"trump\">\n","\n","\n","[1]: https://www.nytimes.com/interactive/2023/10/27/technology/twitter-x-elon-musk-anniversary.html"],"metadata":{"id":"IWxAeUl6aYKK"}},{"cell_type":"markdown","source":["Download the data."],"metadata":{"id":"d-xNfhaRfQ8B"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfP6fDQyYUrS"},"outputs":[],"source":["!mkdir -p datasets/\n","!wget https://hyperion.bbirke.de/data/datasets/data_huang_devansh.csv -O datasets/data_huang_devansh.csv"]},{"cell_type":"markdown","source":["The data is stored as a `.csv` file and contains $2$ columns:\n","\n","* **Content** = the tweet of user from the socal media plattform twitter.\n","* **Label** = class label of the tweet. $0$ - no offensive language $1$ - offensive language\n","\n","## Hints\n","\n","* Please note that there is no predefined train/test split in this dataset. You will need to create the splits manually, for instance, using the scikit-learn function [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n","\n","* Keep an eye on the distribution of class frequencies in your dataset. You can use a stratified sampling approach with the `stratifed` parameter in the `train_test_split` function.\n","\n","* As we have an imbalanced dataset in regards to our class label distribution, we should penalize infrequent classes to prevent the model from being biased towards the majority class. One common approach to address this issue is by using class weighting. This technique helps ensuring that the neural network learns to generalize well across all classes, leading to more robust classification performance.\\\n","You can apply it by using the scikit-learn function [sklearn.utils.class_weight.compute_class_weight](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html), which creates a vector of inverse class frequencies as weights. The resulting `numpy.ndarray` can then be converted to `torch.tensor` (of `dtype=torch.float`) and then be passed as an argument during the instantiation of our loss object with the `weight` parameter.\n","\n","* Accuracy can be a misleading metric in the context of imbalanced datasets because it doesn't consider the distribution of classes. In an imbalanced dataset, where one class is significantly more prevalent than others, a classifier can achieve high accuracy by simply predicting the majority class for every instance.\\\n","For example, if you have a dataset where $95\\%$ of the samples belong to class **A** and only $5\\%$ belong to class **B**, a classifier that always predicts class **A** will achieve $95\\%$ accuracy.\\\n","Instead, metrics like precision, recall, and F1-Score are more informative in imbalanced datasets. Precision measures the proportion of true positive predictions among all positive predictions, while recall measures the proportion of true positives among all actual positives. The F1-Score is the harmonic mean of precision and recall, providing a balance between the two metrics.\\\n","You can calculate the F1-Score by using the scikit-learn function [sklearn.metrics.f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score).\n"],"metadata":{"id":"FAon8xW9ZMvp"}}]}